# ðŸ““ Vekku Project Journal
**Entry:** 005
**Date:** 2025-12-17
**Phase:** Refining

## Context
Just yesterday (Entry 004), we decided to stick with the "Standard" Recursive Splitter for stability. However, reality hits hard. The standard splitter was chopping content into too many arbitrary pieces, failing to capture the *flow* of ideas. A video about "Fruit" that briefly mentions "Finance" would get chopped mid-sentence or grouped poorly, diluting the relevance of our tags.

The user explicitly asked for "Smart Chunking" based on topic shifts. It was time to remove the training wheels.

## Decisions
We decided to **pivot back** to the "Premium" Semantic Chunking approach we previously hesitated on.

*   **Why?**: Accuracy > Simplicity. If the Brain chunks incorrectly, the tagging is garbage. We need the system to "feel" when the topic changes from *Apples* to *Stock Markets*.
*   **The Algo**: We chose a **Cosine Similarity Window** approach.
    1.  Split text into sentences.
    2.  Embed every sentence.
    3.  Compare Sentence A vs Sentence B.
    4.  If Similarity > Threshold (0.45), merge them.
    5.  If Similarity < Threshold, CUT.

## Implementation
*   **BrainLogic.ts**: Implemented `semanticTextSplit` which executes the logic above.
*   **No new dependencies**: We reused the existing `vector` embedding pipeline found in `getVector`.
*   **Verification**: Wrote a script that successfully split a multi-topic paragraph (Apples -> Stocks -> Python) into 3 distinct, clean chunks.

## Next Steps
This method is computationally more expensive (embedding every sentence). We need to keep an eye on performance. If it drags, we might need to batch the embedding calls to the ONNX runtime.
